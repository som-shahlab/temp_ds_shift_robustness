{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with BigQuery\n",
    "\n",
    "This library offers wrappers around BigQuery connectors through the official Google client library and Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from prediction_utils.extraction_utils.database import BQDatabase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary class that we are going to work with is `BQDatabase`.\n",
    "The only keyword arguments that this class takes are `gcloud_project` and `google_application_credentials`.\n",
    "If not provided, they default to `som-nero-phi-nigam-starr` and `os.path.expanduser(\"~/.config/gcloud/application_default_credentials.json\")` respectively.\n",
    "\n",
    "Let's create a database object called `db` using the defaults:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pi/nigam/envs/anaconda/envs/prediction_utils/lib/python3.7/site-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "db = BQDatabase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this database object, extracting the results of a query to a pandas dataframe is as simple as calling `db.read_sql_query(...)`. \n",
    "\n",
    "`db.read_sql_query` takes a boolean argument `use_bqstorage_api` that defaults to True. This argument toggles whether the query should leverage the BigQuery Storage API. When True, the results will be downloaded significantly faster, but incurs more cost. For small datasets, it may be better to set this argument to False.\n",
    "\n",
    "This function further passes all additional keyword arguments to `pandas.read_gbq()`\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1000/1000 [00:00<00:00, 2504.28rows/s]\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM som-rit-phi-starr-prod.starr_omop_cdm5_deid_lite_latest.person\n",
    "    LIMIT 1000\n",
    "\"\"\"\n",
    "df = db.read_sql_query(query=query, use_bqstorage_api=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>gender_concept_id</th>\n",
       "      <th>year_of_birth</th>\n",
       "      <th>month_of_birth</th>\n",
       "      <th>day_of_birth</th>\n",
       "      <th>birth_DATETIME</th>\n",
       "      <th>race_concept_id</th>\n",
       "      <th>ethnicity_concept_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>provider_id</th>\n",
       "      <th>care_site_id</th>\n",
       "      <th>person_source_value</th>\n",
       "      <th>gender_source_value</th>\n",
       "      <th>gender_source_concept_id</th>\n",
       "      <th>race_source_value</th>\n",
       "      <th>race_source_concept_id</th>\n",
       "      <th>ethnicity_source_value</th>\n",
       "      <th>ethnicity_source_concept_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30360313</td>\n",
       "      <td>0</td>\n",
       "      <td>1974</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>1974-09-23</td>\n",
       "      <td>0</td>\n",
       "      <td>38003563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>3 | 3</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown | Other</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown | Hispanic</td>\n",
       "      <td>38003563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31166460</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>2010-03-21</td>\n",
       "      <td>8527</td>\n",
       "      <td>38003563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>3 | 3</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown | White or Caucasian</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown | Hispanic</td>\n",
       "      <td>38003563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30629316</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>2015-06-18</td>\n",
       "      <td>8515</td>\n",
       "      <td>38003564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>3 | 3</td>\n",
       "      <td>0</td>\n",
       "      <td>Asian | Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-Hispanic/Non-Latino | Declines to State</td>\n",
       "      <td>38003564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30762518</td>\n",
       "      <td>8532</td>\n",
       "      <td>1996</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1996-05-06</td>\n",
       "      <td>0</td>\n",
       "      <td>38003563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1 | 2</td>\n",
       "      <td>8532</td>\n",
       "      <td>Race and Ethnicity Unknown | Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown | Hispanic</td>\n",
       "      <td>38003563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32507595</td>\n",
       "      <td>8507</td>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1994-01-25</td>\n",
       "      <td>0</td>\n",
       "      <td>38003563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2 | 1</td>\n",
       "      <td>8507</td>\n",
       "      <td>Unknown | Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown | Hispanic</td>\n",
       "      <td>38003563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_id  gender_concept_id  year_of_birth  month_of_birth  day_of_birth  \\\n",
       "0   30360313                  0           1974               9            23   \n",
       "1   31166460                  0           2010               3            21   \n",
       "2   30629316                  0           2015               6            18   \n",
       "3   30762518               8532           1996               5             6   \n",
       "4   32507595               8507           1994               1            25   \n",
       "\n",
       "  birth_DATETIME  race_concept_id  ethnicity_concept_id  location_id  \\\n",
       "0     1974-09-23                0              38003563          NaN   \n",
       "1     2010-03-21             8527              38003563          NaN   \n",
       "2     2015-06-18             8515              38003564          NaN   \n",
       "3     1996-05-06                0              38003563          NaN   \n",
       "4     1994-01-25                0              38003563          NaN   \n",
       "\n",
       "   provider_id  care_site_id person_source_value gender_source_value  \\\n",
       "0          NaN           NaN                None               3 | 3   \n",
       "1          NaN           NaN                None               3 | 3   \n",
       "2          NaN           NaN                None               3 | 3   \n",
       "3          NaN           NaN                None               1 | 2   \n",
       "4          NaN           NaN                None               2 | 1   \n",
       "\n",
       "   gender_source_concept_id                     race_source_value  \\\n",
       "0                         0                       Unknown | Other   \n",
       "1                         0          Unknown | White or Caucasian   \n",
       "2                         0                         Asian | Asian   \n",
       "3                      8532  Race and Ethnicity Unknown | Unknown   \n",
       "4                      8507                     Unknown | Unknown   \n",
       "\n",
       "   race_source_concept_id                       ethnicity_source_value  \\\n",
       "0                       0                           Unknown | Hispanic   \n",
       "1                       0                           Unknown | Hispanic   \n",
       "2                       0  Non-Hispanic/Non-Latino | Declines to State   \n",
       "3                       0                           Unknown | Hispanic   \n",
       "4                       0                           Unknown | Hispanic   \n",
       "\n",
       "   ethnicity_source_concept_id  \n",
       "0                     38003563  \n",
       "1                     38003563  \n",
       "2                     38003564  \n",
       "3                     38003563  \n",
       "4                     38003563  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To execute arbitrary SQL, use `db.execute_sql`, which internally calls `client.query(query).result()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = db.execute_sql(query=query).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To write query results to a table in BigQuery without returning the results in Pandas, you can use `db.execute_sql_to_destination_table`. This method requires you to fully specify the destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination='som-nero-phi-nigam-starr.temp_dataset.vignette_table'\n",
    "db.execute_sql_to_destination_table(query=query, destination=destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's query the destination to confirm that the results were written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 0/1000 [00:00<?, ?rows/s]/share/pi/nigam/envs/anaconda/envs/prediction_utils/lib/python3.7/site-packages/pyarrow/util.py:39: FutureWarning: pyarrow.read_schema is deprecated as of 0.17.0, please use pyarrow.ipc.read_schema instead\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/share/pi/nigam/envs/anaconda/envs/prediction_utils/lib/python3.7/site-packages/pyarrow/util.py:39: FutureWarning: pyarrow.read_record_batch is deprecated as of 0.17.0, please use pyarrow.ipc.read_record_batch instead\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "Downloading: 100%|██████████| 1000/1000 [00:01<00:00, 611.99rows/s]\n"
     ]
    }
   ],
   "source": [
    "df2 = db.read_sql_query('SELECT * FROM {destination}'.format(destination=destination))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether it's the same data (note that the order of the rows is not preserved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    df\n",
    "    .sort_values('person_id')\n",
    "    .reset_index(drop=True)\n",
    "    .equals(\n",
    "        df2\n",
    "        .sort_values('person_id')\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also write pandas dataframes to tables in BigQuery using the `to_sql` method.\n",
    "This method takes a `mode` argument with valid values `\"gbq\"` and `\"client\"` that determine whether `pandas.DataFrame.to_gbq` or `client.load_table_from_dataframe` will be used. There are tradeoffs between these two methods, with the primary difference being that the interface to `to_gbq` is more straightforward, but writes all `DATE` columns as `TIMESTAMP`, and serializes data to CSV internally. The `client` approach allows for date columns to be written and uses Parquet to serialize data, but has a more verbose and complex interface. There are also some differences in how the destination table must be formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  4.00s/it]\n"
     ]
    }
   ],
   "source": [
    "# gbq method\n",
    "destination='temp_dataset.vignette_table'\n",
    "project_id='som-nero-phi-nigam-starr'\n",
    "db.to_sql(df=df, destination_table=destination, project_id=project_id, mode='gbq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pi/nigam/envs/anaconda/envs/prediction_utils/lib/python3.7/site-packages/google/cloud/bigquery/_pandas_helpers.py:391: UserWarning: Pyarrow could not determine the type of columns: person_source_value.\n",
      "  \", \".join(field.name for field in unknown_type_fields)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000 rows and 18 columns to som-nero-phi-nigam-starr.temp_dataset.vignette_table\n"
     ]
    }
   ],
   "source": [
    "# client method\n",
    "destination='som-nero-phi-nigam-starr.temp_dataset.vignette_table'\n",
    "db.to_sql(df=df, destination_table=destination, mode='client')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class also provides the capability to stream a query to disk in chunks to the Apache Parquet filetype, using pyarrow with the `db.stream_query` method. For usage, see the docstring in the source code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda-prediction_utils]",
   "language": "python",
   "name": "conda-env-anaconda-prediction_utils-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
