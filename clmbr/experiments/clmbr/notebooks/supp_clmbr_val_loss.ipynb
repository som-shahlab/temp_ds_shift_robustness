{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06601d1c-7a6e-4d88-8355-a1af59d50e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd \n",
    "from ehr_ml.clmbr.dataset import DataLoader\n",
    "from ehr_ml.clmbr.prediction_model import CLMBR\n",
    "from ehr_ml.clmbr import PatientTimelineDataset\n",
    "from ehr_ml.clmbr import convert_patient_data\n",
    "from ehr_ml.clmbr.utils import read_config, read_info\n",
    "from ehr_ml.clmbr.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5407cce8-0052-44d8-9bf7-be393fa23bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dir = \"/local-scratch/nigam/projects/lguo/temp_ds_shift_robustness/clmbr/experiments/clmbr/clmbr_artifacts/infos/2009_2012\"\n",
    "info = read_info(os.path.join(info_dir,'info.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb929fa-ab8b-44d2-8699-27b71c1af6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort = pd.read_parquet(\n",
    "    os.path.join(\n",
    "        \"/local-scratch/nigam/projects/lguo/temp_ds_shift_robustness/clmbr/cohorts/admissions/cohort\",\n",
    "        \"cohort_split.parquet\",\n",
    "    )\n",
    ")\n",
    "\n",
    "df_cohort = df_cohort.assign(\n",
    "    date = pd.to_datetime(df_cohort['admit_date']).dt.date\n",
    ")\n",
    "\n",
    "train = df_cohort.query(\n",
    "    f\"fold_id!=['val','test','1'] and admission_year==[2009,2010,2011,2012]\"\n",
    ")\n",
    "\n",
    "# use same validation set as clmbr pretraining\n",
    "val = df_cohort.query(\n",
    "    f\"fold_id==['1'] and admission_year==[2009,2010,2011,2012]\"\n",
    ")\n",
    "\n",
    "# convert patient ids and save to train_splits path\n",
    "train_person_ids, train_day_ids = convert_patient_data(\n",
    "    info['extract_dir'], \n",
    "    train['person_id'], \n",
    "    train['date']\n",
    ")\n",
    "\n",
    "val_person_ids, val_day_ids = convert_patient_data(\n",
    "    info['extract_dir'], \n",
    "    val['person_id'], \n",
    "    val['date']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d555220-6335-4cad-9895-1f162543a0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29061, 7267)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_person_ids), len(val_person_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee38de36-e1f2-4fb2-bac8-5ef3bcb16b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PatientTimelineDataset(\n",
    "    os.path.join(info[\"extract_dir\"], \"extract.db\"),\n",
    "    os.path.join(info[\"extract_dir\"], \"ontology.db\"),\n",
    "    os.path.join(info_dir, \"info.json\"),\n",
    "    ([0 for _ in train_person_ids], train_person_ids, train_day_ids),\n",
    "    ([0 for _ in val_person_ids], val_person_ids, val_day_ids),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eda89c4b-3e53-49bf-ab36-ffa17bc18081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating gru model 0\n",
      "gru model 0 loss: 0.6733505258505995\n",
      "evaluating gru model 11\n",
      "gru model 11 loss: 0.7340359112078493\n",
      "evaluating gru model 26\n",
      "gru model 26 loss: 0.7286979989572004\n",
      "evaluating gru model 12\n",
      "gru model 12 loss: 0.68930495665832\n",
      "evaluating gru model 7\n",
      "gru model 7 loss: 0.6976799504323439\n",
      "evaluating gru model 6\n",
      "gru model 6 loss: 0.72289858690717\n",
      "evaluating gru model 8\n",
      "gru model 8 loss: 0.7338464646176859\n",
      "evaluating gru model 17\n",
      "gru model 17 loss: 0.7290476154197346\n",
      "evaluating gru model 22\n",
      "gru model 22 loss: 0.6835146051916209\n",
      "evaluating gru model 1\n",
      "gru model 1 loss: 0.6924780017950318\n",
      "evaluating gru model 18\n",
      "gru model 18 loss: 0.6726470433852889\n",
      "evaluating gru model 15\n",
      "gru model 15 loss: 0.6940031688321721\n",
      "evaluating gru model 24\n",
      "gru model 24 loss: 0.7024940489368006\n",
      "evaluating gru model 23\n",
      "gru model 23 loss: 0.7359668531201102\n",
      "evaluating gru model 19\n",
      "gru model 19 loss: 0.6872853826392781\n",
      "evaluating gru model 3\n",
      "gru model 3 loss: 0.6918611932884563\n",
      "evaluating gru model 20\n",
      "gru model 20 loss: 0.7319436351006682\n",
      "evaluating gru model 25\n",
      "gru model 25 loss: 0.6872007311745123\n",
      "evaluating gru model 10\n",
      "gru model 10 loss: 0.6881967755881223\n",
      "evaluating gru model 4\n",
      "gru model 4 loss: 0.6949433169581674\n",
      "evaluating gru model 21\n",
      "gru model 21 loss: 0.7003278461369601\n",
      "evaluating gru model 5\n",
      "gru model 5 loss: 0.7320617762478915\n",
      "evaluating gru model 2\n",
      "gru model 2 loss: 0.7375680655241013\n",
      "evaluating gru model 13\n",
      "gru model 13 loss: 0.6896676522764292\n",
      "evaluating gru model 16\n",
      "gru model 16 loss: 0.6885070868513801\n",
      "evaluating gru model 14\n",
      "gru model 14 loss: 0.7295802723277699\n",
      "evaluating gru model 9\n",
      "gru model 9 loss: 0.6705787276679819\n",
      "evaluating transformer model 0\n",
      "transformer model 0 loss: 1.0224953659556129\n",
      "evaluating transformer model 29\n",
      "transformer model 29 loss: 0.7505447939038277\n",
      "evaluating transformer model 35\n",
      "transformer model 35 loss: 0.7551965266466141\n",
      "evaluating transformer model 11\n",
      "transformer model 11 loss: 0.8594234822825952\n",
      "evaluating transformer model 26\n",
      "transformer model 26 loss: 0.7473070445385847\n",
      "evaluating transformer model 12\n",
      "transformer model 12 loss: 1.00552507286722\n",
      "evaluating transformer model 7\n",
      "transformer model 7 loss: 0.8366144665262916\n",
      "evaluating transformer model 6\n",
      "transformer model 6 loss: 1.024041404778307\n",
      "evaluating transformer model 31\n",
      "transformer model 31 loss: 0.7499669675122608\n",
      "evaluating transformer model 8\n",
      "transformer model 8 loss: 1.0262725468386302\n",
      "evaluating transformer model 17\n",
      "transformer model 17 loss: 0.8441030545668169\n",
      "evaluating transformer model 22\n",
      "transformer model 22 loss: 1.028380880301649\n",
      "evaluating transformer model 1\n",
      "transformer model 1 loss: 0.8391446234150366\n",
      "evaluating transformer model 18\n",
      "transformer model 18 loss: 1.0326842950149016\n",
      "evaluating transformer model 15\n",
      "transformer model 15 loss: 0.8509373292326927\n",
      "evaluating transformer model 24\n",
      "transformer model 24 loss: 0.8276681859384883\n",
      "evaluating transformer model 23\n",
      "transformer model 23 loss: 0.8678554980592295\n",
      "evaluating transformer model 34\n",
      "transformer model 34 loss: 0.8177652616392482\n",
      "evaluating transformer model 19\n",
      "transformer model 19 loss: 0.8486816348000006\n",
      "evaluating transformer model 27\n",
      "transformer model 27 loss: 0.8268513178283518\n",
      "evaluating transformer model 33\n",
      "transformer model 33 loss: 0.7583024671131914\n",
      "evaluating transformer model 30\n",
      "transformer model 30 loss: 0.8303331732749939\n",
      "evaluating transformer model 37\n",
      "transformer model 37 loss: 0.7567819878458977\n",
      "evaluating transformer model 3\n",
      "transformer model 3 loss: 0.8415438255125826\n",
      "evaluating transformer model 28\n",
      "transformer model 28 loss: 0.8159596926786683\n",
      "evaluating transformer model 20\n",
      "transformer model 20 loss: 1.0282038727944547\n",
      "evaluating transformer model 44\n",
      "transformer model 44 loss: 0.8343365124680779\n",
      "evaluating transformer model 25\n",
      "transformer model 25 loss: 0.7443756610155106\n",
      "evaluating transformer model 38\n",
      "transformer model 38 loss: 0.8416600525379181\n",
      "evaluating transformer model 10\n",
      "transformer model 10 loss: 1.0270237976854497\n",
      "evaluating transformer model 4\n",
      "transformer model 4 loss: 1.0254353833469478\n",
      "evaluating transformer model 21\n",
      "transformer model 21 loss: 0.8632591529326006\n",
      "evaluating transformer model 5\n",
      "transformer model 5 loss: 0.8378103991801088\n",
      "evaluating transformer model 32\n",
      "transformer model 32 loss: 0.8220606351440604\n",
      "evaluating transformer model 43\n",
      "transformer model 43 loss: 0.7584980103102598\n",
      "evaluating transformer model 2\n",
      "transformer model 2 loss: 1.022423960945823\n",
      "evaluating transformer model 40\n",
      "transformer model 40 loss: 0.8312820331616835\n",
      "evaluating transformer model 13\n",
      "transformer model 13 loss: 0.8451400256969712\n",
      "evaluating transformer model 39\n",
      "transformer model 39 loss: 0.7561198926784776\n",
      "evaluating transformer model 42\n",
      "transformer model 42 loss: 0.8247490599751472\n",
      "evaluating transformer model 16\n",
      "transformer model 16 loss: 1.0250114635987715\n",
      "evaluating transformer model 47\n",
      "transformer model 47 loss: 0.7704548503864895\n",
      "evaluating transformer model 41\n",
      "transformer model 41 loss: 0.7603355117819526\n",
      "evaluating transformer model 45\n",
      "transformer model 45 loss: 0.7689945948394862\n",
      "evaluating transformer model 14\n",
      "transformer model 14 loss: 1.023786193945191\n",
      "evaluating transformer model 36\n",
      "transformer model 36 loss: 0.8408860035917975\n",
      "evaluating transformer model 9\n",
      "transformer model 9 loss: 0.8489120406183329\n",
      "evaluating transformer model 46\n",
      "transformer model 46 loss: 0.8296539194204591\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import binary_cross_entropy_with_logits as bce\n",
    "\n",
    "losses = {}\n",
    "\n",
    "for encoder in ['gru','transformer']:\n",
    "    \n",
    "    model_dir = f\"/local-scratch/nigam/projects/lguo/temp_ds_shift_robustness/clmbr/experiments/clmbr/clmbr_artifacts/models/2009_2012/{encoder}/\"\n",
    "    models = os.listdir(model_dir)\n",
    "    losses[encoder]={}\n",
    "    \n",
    "    for model in models:\n",
    "        print(f\"evaluating {encoder} model {model}\")\n",
    "        \n",
    "        m = CLMBR.from_pretrained(os.path.join(model_dir,model))\n",
    "\n",
    "        m.config['day_dropout']=0\n",
    "        m.config['code_dropout']=0\n",
    "\n",
    "        #trainer = Trainer(m)\n",
    "        #losses[model] = trainer.evaluate(dataset, num_batches=len(val_person_ids),)\n",
    "\n",
    "        m.eval()\n",
    "\n",
    "        batches = DataLoader(\n",
    "            dataset=dataset,\n",
    "            threshold=m.config['num_first'],\n",
    "            is_val=True,\n",
    "            batch_size=2000,\n",
    "        )\n",
    "\n",
    "        num_batches = len(batches)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss = 0\n",
    "            for batch in batches:\n",
    "                out = m.forward(batch)\n",
    "\n",
    "                (\n",
    "                    non_text_indices,\n",
    "                    non_text_expected_output,\n",
    "                    seen_before,\n",
    "                    non_text_indices1,\n",
    "                    non_text_expected_output1,\n",
    "                    seen_before1,\n",
    "                ) = batch['task']\n",
    "\n",
    "                loss += bce(out['values'],non_text_expected_output,reduction='mean').cpu().numpy()\n",
    "        \n",
    "        loss/=num_batches\n",
    "        \n",
    "        print(f\"{encoder} model {model} loss: {loss}\")\n",
    "        losses[encoder][model]=loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bfaf623-fdb3-42ec-911e-f8660d24aa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((\n",
    "    (\n",
    "        pd.DataFrame.from_dict(losses[x],orient='index')\n",
    "        .reset_index()\n",
    "        .rename(columns={'index':'model_num',0:'loss'})\n",
    "        .assign(encoder=x)\n",
    "    ) for x in losses.keys()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89bc1acd-19de-43ad-b23c-7868baa0755a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_num</th>\n",
       "      <th>loss</th>\n",
       "      <th>encoder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.673351</td>\n",
       "      <td>gru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0.734036</td>\n",
       "      <td>gru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>0.728698</td>\n",
       "      <td>gru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>0.689305</td>\n",
       "      <td>gru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.697680</td>\n",
       "      <td>gru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>45</td>\n",
       "      <td>0.768995</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>14</td>\n",
       "      <td>1.023786</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>36</td>\n",
       "      <td>0.840886</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>9</td>\n",
       "      <td>0.848912</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>46</td>\n",
       "      <td>0.829654</td>\n",
       "      <td>transformer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_num      loss      encoder\n",
       "0          0  0.673351          gru\n",
       "1         11  0.734036          gru\n",
       "2         26  0.728698          gru\n",
       "3         12  0.689305          gru\n",
       "4          7  0.697680          gru\n",
       "..       ...       ...          ...\n",
       "43        45  0.768995  transformer\n",
       "44        14  1.023786  transformer\n",
       "45        36  0.840886  transformer\n",
       "46         9  0.848912  transformer\n",
       "47        46  0.829654  transformer\n",
       "\n",
       "[75 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcc6c52f-2f59-4128-9ff1-e52e4e65c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('tables/clmbr_losses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2e8fe7-4ab0-423b-a002-3e3e53bcda00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
