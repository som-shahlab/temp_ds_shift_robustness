{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/share/pi/nigam/projects/spfohl/cohorts/admissions/optum/'\n",
    "predictions_path = os.path.join(data_path, 'experiments', 'baseline_tuning_fold_1_10', 'performance', 'LOS_7', '0.yaml', '1', 'output_df.parquet')\n",
    "cohort_path = os.path.join(data_path, 'cohort', 'cohort.parquet')\n",
    "row_id_map_path = os.path.join(data_path, 'merged_features_binary', 'features_sparse', 'features_row_id_map.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.read_parquet(predictions_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = pd.read_parquet(cohort_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_id_map = pd.read_parquet(row_id_map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features_row_id</th>\n",
       "      <th>prediction_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-9223363366502185856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-9223362673657268414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-9223362053444238164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-9223361452100897490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-9223360812677213811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8074566</th>\n",
       "      <td>8074566</td>\n",
       "      <td>9223364539900589339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8074567</th>\n",
       "      <td>8074567</td>\n",
       "      <td>9223365295068207882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8074568</th>\n",
       "      <td>8074568</td>\n",
       "      <td>9223366169655560425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8074569</th>\n",
       "      <td>8074569</td>\n",
       "      <td>9223367109999326759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8074570</th>\n",
       "      <td>8074570</td>\n",
       "      <td>9223369458509783891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8074571 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         features_row_id        prediction_id\n",
       "0                      0 -9223363366502185856\n",
       "1                      1 -9223362673657268414\n",
       "2                      2 -9223362053444238164\n",
       "3                      3 -9223361452100897490\n",
       "4                      4 -9223360812677213811\n",
       "...                  ...                  ...\n",
       "8074566          8074566  9223364539900589339\n",
       "8074567          8074567  9223365295068207882\n",
       "8074568          8074568  9223366169655560425\n",
       "8074569          8074569  9223367109999326759\n",
       "8074570          8074570  9223369458509783891\n",
       "\n",
       "[8074571 rows x 2 columns]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>admit_date</th>\n",
       "      <th>discharge_date</th>\n",
       "      <th>hospital_mortality</th>\n",
       "      <th>month_mortality</th>\n",
       "      <th>LOS_days</th>\n",
       "      <th>LOS_7</th>\n",
       "      <th>readmission_30</th>\n",
       "      <th>age_in_years</th>\n",
       "      <th>age_group</th>\n",
       "      <th>race_eth</th>\n",
       "      <th>gender_concept_name</th>\n",
       "      <th>prediction_id</th>\n",
       "      <th>fold_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2017-09-12</td>\n",
       "      <td>2017-09-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>[55-65)</td>\n",
       "      <td>Other</td>\n",
       "      <td>MALE</td>\n",
       "      <td>1669980515859799912</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2007-09-17</td>\n",
       "      <td>2007-09-18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>[18-30)</td>\n",
       "      <td>Other</td>\n",
       "      <td>MALE</td>\n",
       "      <td>-3060212163314143226</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>2007-06-17</td>\n",
       "      <td>2007-06-18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>[18-30)</td>\n",
       "      <td>Other</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>2688580955788010273</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>2009-03-02</td>\n",
       "      <td>2009-03-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>[30-45)</td>\n",
       "      <td>Other</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>-751964920177342014</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>2005-02-20</td>\n",
       "      <td>2005-02-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>[55-65)</td>\n",
       "      <td>Other</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>-470516056504384768</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_id admit_date discharge_date  hospital_mortality  month_mortality  \\\n",
       "0          3 2017-09-12     2017-09-14                   0                0   \n",
       "1          4 2007-09-17     2007-09-18                   0                0   \n",
       "2         11 2007-06-17     2007-06-18                   0                0   \n",
       "3         14 2009-03-02     2009-03-04                   0                0   \n",
       "4         16 2005-02-20     2005-02-22                   0                0   \n",
       "\n",
       "   LOS_days  LOS_7  readmission_30  age_in_years age_group race_eth  \\\n",
       "0         2      0               0            58   [55-65)    Other   \n",
       "1         1      0               0            29   [18-30)    Other   \n",
       "2         1      0               0            27   [18-30)    Other   \n",
       "3         2      0               0            35   [30-45)    Other   \n",
       "4         2      0               0            62   [55-65)    Other   \n",
       "\n",
       "  gender_concept_name        prediction_id fold_id  \n",
       "0                MALE  1669980515859799912    test  \n",
       "1                MALE -3060212163314143226    test  \n",
       "2              FEMALE  2688580955788010273       7  \n",
       "3              FEMALE  -751964920177342014       3  \n",
       "4              FEMALE  -470516056504384768       8  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phase</th>\n",
       "      <th>outputs</th>\n",
       "      <th>pred_probs</th>\n",
       "      <th>labels</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>val</td>\n",
       "      <td>-0.311713</td>\n",
       "      <td>0.334550</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val</td>\n",
       "      <td>-0.869886</td>\n",
       "      <td>0.116189</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>val</td>\n",
       "      <td>-1.979475</td>\n",
       "      <td>0.009725</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>val</td>\n",
       "      <td>-0.322860</td>\n",
       "      <td>0.325983</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>val</td>\n",
       "      <td>-0.782082</td>\n",
       "      <td>0.135438</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533932</th>\n",
       "      <td>test</td>\n",
       "      <td>-0.252077</td>\n",
       "      <td>0.366276</td>\n",
       "      <td>1</td>\n",
       "      <td>8074549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533933</th>\n",
       "      <td>test</td>\n",
       "      <td>-0.385773</td>\n",
       "      <td>0.296091</td>\n",
       "      <td>0</td>\n",
       "      <td>8074550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533934</th>\n",
       "      <td>test</td>\n",
       "      <td>-0.637188</td>\n",
       "      <td>0.191029</td>\n",
       "      <td>0</td>\n",
       "      <td>8074552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533935</th>\n",
       "      <td>test</td>\n",
       "      <td>-0.464459</td>\n",
       "      <td>0.253941</td>\n",
       "      <td>0</td>\n",
       "      <td>8074554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533936</th>\n",
       "      <td>test</td>\n",
       "      <td>-0.684945</td>\n",
       "      <td>0.165937</td>\n",
       "      <td>0</td>\n",
       "      <td>8074561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1533937 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        phase   outputs  pred_probs  labels   row_id\n",
       "0         val -0.311713    0.334550       1       31\n",
       "1         val -0.869886    0.116189       0       36\n",
       "2         val -1.979475    0.009725       0       37\n",
       "3         val -0.322860    0.325983       1       51\n",
       "4         val -0.782082    0.135438       0       59\n",
       "...       ...       ...         ...     ...      ...\n",
       "1533932  test -0.252077    0.366276       1  8074549\n",
       "1533933  test -0.385773    0.296091       0  8074550\n",
       "1533934  test -0.637188    0.191029       0  8074552\n",
       "1533935  test -0.464459    0.253941       0  8074554\n",
       "1533936  test -0.684945    0.165937       0  8074561\n",
       "\n",
       "[1533937 rows x 5 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EarlyStopping mode auto is unknown, fallback to auto mode.\n",
      "EarlyStopping mode set to min for monitoring val_loss.\n",
      "GPU available: False, used: False\n",
      "No environment variable for node rank defined. Set as 0.\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "-----------------------------\n",
      "0 | layer | Linear | 2     \n",
      "Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[2.4244]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.9988], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f25a593ad40>\n",
      "Traceback (most recent call last):\n",
      "  File \"/share/pi/nigam/envs/anaconda/envs/prediction_utils/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 962, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/share/pi/nigam/envs/anaconda/envs/prediction_utils/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 942, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/share/pi/nigam/envs/anaconda/envs/prediction_utils/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/share/pi/nigam/envs/anaconda/envs/prediction_utils/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/share/pi/nigam/envs/anaconda/envs/prediction_utils/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "class LogProbModel(LightningModule):\n",
    "\n",
    "    def __init__(self, apply_log_transform=True):\n",
    "        super().__init__()\n",
    "        self.layer = torch.nn.Linear(1, 2, bias=True)\n",
    "        self.apply_log_transform = apply_log_transform\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "#         return torch.relu(self.l1(x.view(x.size(0), -1)))\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.unsqueeze(1)\n",
    "#         print(x)\n",
    "        if self.apply_log_transform:\n",
    "            x = torch.log(x)\n",
    "        y_hat = self.forward(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "    \n",
    "class LogProbModel2(LightningModule):\n",
    "\n",
    "    def __init__(self, apply_log_transform=True):\n",
    "        super().__init__()\n",
    "        self.layer = torch.nn.Linear(1, 1, bias=True)\n",
    "        self.apply_log_transform = apply_log_transform\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "    \n",
    "    def forward_on_batch(self, batch):\n",
    "        x, y = batch\n",
    "        x = x.unsqueeze(1)\n",
    "        y = y.unsqueeze(1)\n",
    "        if self.apply_log_transform:\n",
    "            x = torch.log(x)\n",
    "        y_hat = self.forward(x)\n",
    "        return F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return {'loss': self.forward_on_batch(batch)}\n",
    "    \n",
    "\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         optimizer = torch.optim.Adam(self.parameters(), lr=0.1)\n",
    "#         return optimizer\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.1)\n",
    "        scheduler = {\n",
    "            'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer),\n",
    "            'monitor': 'val_loss',\n",
    "            'interval': 'epoch',\n",
    "            'frequency': 1\n",
    "        }\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return {'val_loss': self.forward_on_batch(batch)}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        return {'val_loss': avg_loss}\n",
    "\n",
    "\n",
    "train_df = pred_df.query('phase == \"val\"')\n",
    "val_df = pred_df.query('phase == \"test\"')\n",
    "train_dataset = torch.utils.data.TensorDataset(torch.FloatTensor(train_df.pred_probs), torch.FloatTensor(train_df.labels))\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1024, num_workers=4)\n",
    "val_dataset = torch.utils.data.TensorDataset(torch.FloatTensor(val_df.pred_probs.values), torch.FloatTensor(val_df.labels.values))\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1024, num_workers=4)\n",
    "model = LogProbModel2()\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0,\n",
    "    verbose=True,\n",
    "    patience=50\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=100, \n",
    "    early_stop_callback=early_stop_callback, \n",
    "    progress_bar_refresh_rate=0, \n",
    "    checkpoint_callback=False, \n",
    "    logger=False,\n",
    "    gpus=1 if torch.cuda.is_available() else 0\n",
    ")\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "print(model.layer.weight)\n",
    "print(model.layer.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pred_df.query('phase == \"val\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalibrationEvaluator:\n",
    "    def get_calibration_df(\n",
    "        self,\n",
    "        df,\n",
    "        group_vars=[\"config_filename\", \"phase\", \"task\", \"attribute\", \"group\"],\n",
    "        df_eval=None,\n",
    "    ):\n",
    "        group_vars = [var for var in group_vars if var in df.columns]\n",
    "        model_dict = {}\n",
    "        calibration_dict = {}\n",
    "        for group, df_grouped in df.groupby(group_vars):\n",
    "            df_grouped = df_grouped.query(\"pred_probs > 0\")\n",
    "            log_probs = np.log(df_grouped.pred_probs.values.reshape(-1, 1))\n",
    "            model_dict[group] = LogisticRegression(solver=\"lbfgs\", penalty=\"none\")\n",
    "            model_dict[group].fit(log_probs, df_grouped.labels.values)\n",
    "            if df_eval is None:\n",
    "                calibration_dict[group] = df_grouped.assign(\n",
    "                    density_conditional_y1=model_dict[group].predict_proba(log_probs)[\n",
    "                        :, -1\n",
    "                    ]\n",
    "                ).reset_index(drop=True)\n",
    "            else:\n",
    "                df_eval_grouped = self.filter_by_group_spec(df_eval, group_vars, group)\n",
    "                df_eval_grouped = df_eval_grouped.query(\"pred_probs > 0\")\n",
    "                log_probs = np.log(df_eval_grouped.pred_probs.values.reshape(-1, 1))\n",
    "                calibration_dict[group] = df_eval_grouped.assign(\n",
    "                    density_conditional_y1=model_dict[group].predict_proba(log_probs)[\n",
    "                        :, -1\n",
    "                    ]\n",
    "                ).reset_index(drop=True)\n",
    "        calibration_df = pd.concat(calibration_dict).reset_index(drop=True)\n",
    "        return calibration_df\n",
    "\n",
    "    def get_calibration_df_combined(\n",
    "        self,\n",
    "        df,\n",
    "        group_vars=[\n",
    "            \"sensitive_attribute\",\n",
    "            \"config_filename\",\n",
    "            \"phase\",\n",
    "            \"task\",\n",
    "            \"attribute\",\n",
    "        ],\n",
    "    ):\n",
    "        calibration_df_group = self.get_calibration_df(\n",
    "            df, group_vars=group_vars + [\"group\"]\n",
    "        )\n",
    "        calibration_df_overall = self.get_calibration_df(df, group_vars=group_vars)\n",
    "        calibration_df = calibration_df_group.merge(\n",
    "            calibration_df_overall.rename(\n",
    "                columns={\"density_conditional_y1\": \"density_conditional_y1_overall\"}\n",
    "            )\n",
    "        )\n",
    "        return calibration_df\n",
    "\n",
    "    def get_calibration_result(\n",
    "        self, df, group_vars=[\"config_filename\", \"phase\", \"task\", \"attribute\", \"group\"],\n",
    "    ):\n",
    "        group_vars = [var for var in group_vars if var in df.columns]\n",
    "        return (\n",
    "            df.assign(\n",
    "                brier_diff_signed=lambda x: x.labels - x.pred_probs,\n",
    "                brier_diff_squared=lambda x: x.brier_diff_signed ** 2,\n",
    "                calib_diff_signed=lambda x: x.density_conditional_y1 - x.pred_probs,\n",
    "                calib_diff_squared=lambda x: x.calib_diff_signed ** 2,\n",
    "                calib_density_diff_signed=lambda x: x.density_conditional_y1\n",
    "                - x.density_conditional_y1_overall,\n",
    "                calib_density_diff_squared=lambda x: x.calib_density_diff_signed ** 2,\n",
    "            )\n",
    "            .groupby(group_vars)\n",
    "            .agg(\n",
    "                brier=(\"brier_diff_squared\", lambda x: x.mean()),\n",
    "                brier_signed=(\"brier_diff_signed\", lambda x: x.mean()),\n",
    "                calib_error=(\"calib_diff_squared\", lambda x: x.mean()),\n",
    "                calib_error_signed=(\"calib_diff_signed\", lambda x: x.mean()),\n",
    "                calib_group_error=(\"calib_density_diff_squared\", lambda x: x.mean()),\n",
    "                calib_group_error_signed=(\n",
    "                    \"calib_density_diff_signed\",\n",
    "                    lambda x: x.mean(),\n",
    "                ),\n",
    "            )\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "    def filter_by_group_spec(self, df, group_vars, group_values):\n",
    "        for group_var, group_value in zip(group_vars, group_values):\n",
    "            df = df.loc[df[group_var] == group_value]\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.6 s, sys: 12.5 s, total: 23.1 s\n",
      "Wall time: 925 ms\n",
      "[array([[2.44633899]]), array([1.98917973])]\n",
      "CPU times: user 8.53 s, sys: 2.65 s, total: 11.2 s\n",
      "Wall time: 6.5 s\n",
      "[array([[2.44681725]]), array([1.98977588])]\n"
     ]
    }
   ],
   "source": [
    "model_sk = LogisticRegression(solver=\"lbfgs\", penalty=\"none\")\n",
    "%time model_sk.fit(np.log(train_df.pred_probs.values.reshape(-1, 1)), train_df.labels.values)\n",
    "print([model_sk.coef_, model_sk.intercept_])\n",
    "\n",
    "model_sk = SGDClassifier(loss='log', learning_rate='adaptive', eta0=1e-1, max_iter=1000, alpha=1e-12)\n",
    "\n",
    "%time model_sk.fit(np.log(train_df.pred_probs.values.reshape(-1, 1)), train_df.labels.values)\n",
    "print([model_sk.coef_, model_sk.intercept_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_train_df = pd.concat([train_df for i in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phase</th>\n",
       "      <th>outputs</th>\n",
       "      <th>pred_probs</th>\n",
       "      <th>labels</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>val</td>\n",
       "      <td>-1.094916</td>\n",
       "      <td>0.079028</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val</td>\n",
       "      <td>-2.456556</td>\n",
       "      <td>0.003679</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>val</td>\n",
       "      <td>-3.585434</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>val</td>\n",
       "      <td>-0.885466</td>\n",
       "      <td>0.112826</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>val</td>\n",
       "      <td>-1.538378</td>\n",
       "      <td>0.027455</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17873</th>\n",
       "      <td>val</td>\n",
       "      <td>-1.423776</td>\n",
       "      <td>0.037314</td>\n",
       "      <td>0</td>\n",
       "      <td>198601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17874</th>\n",
       "      <td>val</td>\n",
       "      <td>-1.970004</td>\n",
       "      <td>0.011250</td>\n",
       "      <td>0</td>\n",
       "      <td>198627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17875</th>\n",
       "      <td>val</td>\n",
       "      <td>-3.218438</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0</td>\n",
       "      <td>198629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17876</th>\n",
       "      <td>val</td>\n",
       "      <td>-2.217583</td>\n",
       "      <td>0.006336</td>\n",
       "      <td>0</td>\n",
       "      <td>198635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17877</th>\n",
       "      <td>val</td>\n",
       "      <td>-1.353804</td>\n",
       "      <td>0.044619</td>\n",
       "      <td>0</td>\n",
       "      <td>198640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1787800 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      phase   outputs  pred_probs  labels  row_id\n",
       "0       val -1.094916    0.079028       0      16\n",
       "1       val -2.456556    0.003679       0      21\n",
       "2       val -3.585434    0.000268       0      24\n",
       "3       val -0.885466    0.112826       0      35\n",
       "4       val -1.538378    0.027455       0      37\n",
       "...     ...       ...         ...     ...     ...\n",
       "17873   val -1.423776    0.037314       0  198601\n",
       "17874   val -1.970004    0.011250       0  198627\n",
       "17875   val -3.218438    0.000618       0  198629\n",
       "17876   val -2.217583    0.006336       0  198635\n",
       "17877   val -1.353804    0.044619       0  198640\n",
       "\n",
       "[1787800 rows x 5 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.7 s, sys: 27 s, total: 50.7 s\n",
      "Wall time: 1.97 s\n",
      "[array([[0.85900524]]), array([-0.49485377])]\n",
      "CPU times: user 25.2 s, sys: 3.6 s, total: 28.8 s\n",
      "Wall time: 24.1 s\n",
      "[array([[0.86293342]]), array([-0.48265425])]\n"
     ]
    }
   ],
   "source": [
    "model_sk = LogisticRegression(solver=\"lbfgs\", penalty=\"none\")\n",
    "%time model_sk.fit(np.log(big_train_df.pred_probs.values.reshape(-1, 1)), big_train_df.labels.values)\n",
    "print([model_sk.coef_, model_sk.intercept_])\n",
    "\n",
    "model_sk = SGDClassifier(\n",
    "    loss='log', \n",
    "    early_stopping=True, \n",
    "    learning_rate='adaptive', \n",
    "    eta0=1e-1, \n",
    "    max_iter=100, \n",
    "    alpha=1e-12\n",
    ")\n",
    "\n",
    "%time model_sk.fit(np.log(big_train_df.pred_probs.values.reshape(-1, 1)), big_train_df.labels.values)\n",
    "print([model_sk.coef_, model_sk.intercept_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in constructing an estimator of the integrated calibration index (ICI) and matching conditional frequency metric (MCF) on a test set. These measures rely on estimating nuisance densities of p(y|f(x)) for the full test set and for each group. For scalability reasons, it is desired to be able to train models for these densities using minibatch SGD, which performs best with a validation set for early stopping. Furthermore, this approach can be improved by using a cross-fitting estimator, repeating the entire process on separate folds of the data.\n",
    "\n",
    "For the standard procedure (no cross-fitting)\n",
    "    * Split data into 90/10 split, stratified by group and outcome\n",
    "    * For each group, train a logistic regression model using the corresponding within-group 10% as early-stopping validation. Repeat for the aggregate sample.\n",
    "    * Compute ICI and MCF as plug-in estimates\n",
    "   \n",
    "For the cross-fitting procedure\n",
    "    * Split data in to K-folds, stratified by group and outcome\n",
    "    * For each fold i, perform the standard estimation procedure, training with data not in fold i and evaluating on fold i\n",
    "    * Take the mean of each value of interest across the folds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
